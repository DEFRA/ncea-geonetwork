Steps for migration to elasticsearch cluster with self signed ssl certificate for application connectivity:

The intention is to deploy all resources into the same namespace, this is 'nceafrontend'
Currently geonetwork, elasticsearch and kibana are in the geonetwork namespace but we will rationalise this into one namespace. nceafrontend.

Prior to updating the geonetwork pipeline and deploying that way. We should test by running the helm chart locally.

Use the chart in 'charts\geonetwork-es'

IF you are testing this chart in the sandbox you will need the following templates:

- geonetwork-priv-fileshare-pvc.yaml
- geonetwork-priv-fileshare-storageclass.yaml

To test manually in dev you will NOT need them. Move them to a temporary location to test.
TODO: paramaterize with value.

Key values to populate in the local values file:

geoMetaDataFileShareName: ncea-enricher-fileshare-pvc (this pvc exists in the nceafrontend already so we do not need to creat a storage class)

1. Notify the team that geonetwork will be down in dev.
2. Ensure you are in the development aks context 'kubectl config use-context DEVNCEINFAK1401'
Test the 'geonetwork-es' chart locally by deploying directly to the nceafrontend namespace
3. Ensure that you have a values file configured for the dev environment. Do not commit to source because it will contain sensitive passwords. This will need to use a geonetwork container image that includes the self signed certificate import.
e.g defra/geonetwork428:20240607.1 or upwards.
4. Uninstall geonetwork from the 'geonetwork' namespace: 'helm uninstall geonetwork-helm-deploy -n geonetwork'
6. Deploy the new elasticsearch cluster. From devops run this pipeline 'https://dev.azure.com/defragovuk/DEFRA-NCEA/_build?definitionId=7086'
7. Deploy the kibana instance. From DevOps trigger this pipeline 'https://dev.azure.com/defragovuk/DEFRA-NCEA/_build?definitionId=7088'
8. Ensure the pods come up and test access to elasticsearch instance with a port forward: 'kubectl port-forward service/elasticsearch-master 9200:9200  -n nceafrontend'
9. Once happy complete a manual install of geonetwork 'helm install geonetwork-helm-escluster .\geonetwork-es\ --values .\geonetwork-es\dev-values.yaml -n nceafrontend' 
10. Once started, do a port forward 'kubectl port-forward service/geonetwork 8080:8080 -n nceafrontend' and log into geonetwork, go into tools -> Delete index and reindex' -> this should clear the elasticsearch index and reindex the data from the database.
11. Ensure the data is viewable from the geonetwork catalogue page, this is front page of geonetwork.'/geonetwork/srv/eng/catalog.search#/home'
12. If data can be seen then it is working as expected. Geonetwork is talking to elasticsearch with a self signed certificate.
13. We can proceed with deploying

Deploying by the pipeline:

The helm chart will inject variables from the variable group so the following values will need to be updated accordingly to ensure successfull deploymnent to the correct namespace.

Variable groups:
geoNetworkAppVariables-dev
geoNetworkAppVariables-test

Variables to update in the library prior to running the pipeline:

aksNamespaceGeoNetwork: currently 'geonetwork' but will change to 'nceafrontend' 
elasticsearchHost: elasticsearch-master
elasticsearchName: elasticsearch-master
kibanaHostName: kibana-kibana
kibanaInstanceName: kibana-kibana

